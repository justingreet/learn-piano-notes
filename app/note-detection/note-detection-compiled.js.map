{"version":3,"sources":["note-detection.js"],"names":[],"mappings":"AAAA;;;;;;AAEA,IAAI,sBAAsB,QAAQ,MAAR,CAAe,mCAAf,CAAtB;;IAEE;AACJ,WADI,uBACJ,CAAY,mBAAZ,EAAiC;;;0BAD7B,yBAC6B;;AAC/B,SAAK,mBAAL,GAA2B,mBAA3B;;;;;;;;AAD+B,QAS/B,CAAK,OAAL,GAAe,IAAf;;;AAT+B,QAY/B,CAAK,MAAL,GAAc,IAAI,YAAJ,CAAiB,KAAK,OAAL,CAA/B,CAZ+B;AAa/B,SAAK,YAAL,GAAoB,IAAI,YAAJ,EAApB;;;AAb+B,QAgB/B,CAAK,WAAL,GAAmB,KAAK,YAAL,CAAkB,UAAlB,CAhBY;AAiB/B,SAAK,mBAAL,CAAyB,aAAzB,CAAuC,KAAK,WAAL,CAAvC,CAjB+B;;AAmB/B,QAAI,QAAQ,SAAR,KAAQ,GAAW;AACrB,cAAQ,GAAR,CAAY,eAAZ,EADqB;KAAX,CAnBmB;;AAuB/B,cAAU,YAAV,GACI,UAAU,YAAV,IACA,UAAU,kBAAV,IACA,UAAU,eAAV,CA1B2B;AA2B/B,cAAU,YAAV,CAAwB,EAAC,OAAO,IAAP,EAAzB,EACI;aAAU,MAAK,aAAL,CAAmB,MAAnB;KAAV,EAAsC,KAD1C,EA3B+B;GAAjC;;;;;;;;;eADI;;kCAsCU,QAAQ;;;;AAEpB,UAAI,oBACA,KAAK,YAAL,CAAkB,uBAAlB,CAA0C,MAA1C,CADA;;;AAFgB,UAMpB,CAAK,QAAL,GAAgB,KAAK,YAAL,CAAkB,cAAlB,EAAhB,CANoB;AAOpB,WAAK,QAAL,CAAc,OAAd,GAAwB,IAAxB;;AAPoB,uBASpB,CAAkB,OAAlB,CAA0B,KAAK,QAAL,CAA1B,CAToB;;AAWpB,aAAO,WAAP,CAAmB;eAAM,OAAK,UAAL;OAAN,EAAyB,EAA5C,EAXoB;;;;iCAeT;;;;;;;SArDT;;;AA6DN,oBAAoB,UAApB,CAA+B,yBAA/B,EACI,uBADJ","file":"note-detection-compiled.js","sourcesContent":["'use strict';\n\nvar noteDetectionModule = angular.module('pianoPitchDetector.note-detection');\n\nclass NoteDetectionController {\n  constructor(noteDetectorService) {\n    this.noteDetectorService = noteDetectorService;\n\n    /**\n     * @type {number} The number of data points we capture from the mic.\n     * This is the smallest power of 2 that allows us to capture at least\n     * 2 instances of the lowest piano note (which has frequency 27.5) at a\n     * sample rate of 44,100. The buffer should capture 9% of a second.\n     */\n    this.BUF_LEN = 4096;\n\n    /** @type {Float32Array} The array that stores the mic data points. */\n    this.buffer = new Float32Array(this.BUF_LEN);\n    this.audioContext = new AudioContext();\n\n    /** @type {number} The sample rate of the audio context. */\n    this.SAMPLE_RATE = this.audioContext.sampleRate;\n    this.noteDetectorService.setSampleRate(this.SAMPLE_RATE);\n\n    var error = function() {\n      console.log('ERROR! ERROR!');\n    };\n\n    navigator.getUserMedia =\n        navigator.getUserMedia ||\n        navigator.webkitGetUserMedia ||\n        navigator.mozGetUserMedia;\n    navigator.getUserMedia(({audio: true}),\n        stream => this.initDetection(stream), error);\n  }\n\n\n  /**\n   * Create an Audio Node for the input from the user's mic, an Audio Node\n   * to analyze that data, and hook them together.\n   * @param stream The media stream from the user's mic\n   */\n  initDetection(stream) {\n    // Create an AudioNode from the stream.\n    var mediaStreamSource =\n        this.audioContext.createMediaStreamSource(stream);\n\n    // Create an analyser node.\n    this.analyser = this.audioContext.createAnalyser();\n    this.analyser.fftSize = 2048;\n    // Take the output of the stream and pass it to the analyser as input.\n    mediaStreamSource.connect(this.analyser);\n\n    window.setInterval(() => this.detectNote(), 94);\n  }\n\n\n  detectNote() {\n    /*this.analyser.getFloatTimeDomainData(this.buffer);\n    var detectedNote = this.noteDetectorService.detectKeyNum(this.buffer);\n\n    document.getElementById('stuff').innerHTML = detectedNote;*/\n  }\n}\n\nnoteDetectionModule.controller('NoteDetectionController',\n    NoteDetectionController);\n"]}